{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、导入数据\n",
    "\n",
    "# 定义路径\n",
    "train_path = r\"D:\\BaiduNetdiskDownload\\FLIR_ADAS_1_3\\aligned\\ImageFolder\\train\"\n",
    "test_path = r\"D:\\BaiduNetdiskDownload\\FLIR_ADAS_1_3\\aligned\\ImageFolder\\test\"\n",
    "\n",
    "# 预处理步骤\n",
    "transform_train = torchvision.transforms.Compose([       \n",
    "        transforms.ToTensor(),  # 转变为(C,H,W)的Tensor格式\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # 归一化，Imagenet数据集的均值和标准差\n",
    "        transforms.RandomHorizontalFlip(),  # 使用RandomHorizontalFlip转换以50%的概率随机水平翻转图像\n",
    "        # transforms.Resize([56, 56]),  # 重新设置图片大小\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        # transforms.Resize([56, 56]),  # 重新设置图片大小\n",
    "])\n",
    "\n",
    "# ImageFolder类的数据集\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_path, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_path, transform=transform_test)\n",
    "# dataloader\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)    # drop_last 丢弃不满一个batch的数据\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.classes)     # label是按照文件夹名顺序排序后存成字典，即{类名:类序号(从0开始)}\n",
    "print(test_dataset.class_to_idx)    # 查看映射关系\n",
    "for i, (inputs, labels) in enumerate(train_iter):\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "    print(inputs.shape, labels) # inputs.shape: b, c, w, h  labels: 一个批次的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、构建模型\n",
    "\n",
    "class IAN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(IAN, self).__init__()\n",
    "        self.Conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.Conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.FC1 = nn.Linear(64*14*14, 512)    # 14*14 是卷积之后的特征图大小\n",
    "        self.FC2 = nn.Linear(512, 256)\n",
    "        self.FC3 = nn.Linear(256, 2)\n",
    "\n",
    "        self.GAP = nn.AdaptiveAvgPool2d([56, 56])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _ = self.GAP(x)                 # 直接用GAP当resize用\n",
    "        _ = self.Conv2(self.Conv1(_))\n",
    "        # print(_.shape)    # debug point\n",
    "        _ = _.view(x.size(0), 64 * 14 * 14)   # 展开为1维向量，方便做全连接操作\n",
    "        _ = self.FC1(_)\n",
    "        _ = self.dropout(_)\n",
    "        _ = self.FC2(_)\n",
    "        _ = self.dropout(_)\n",
    "        y = self.FC3(_)\n",
    "        return y\n",
    "    \n",
    "model = IAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3、开始训练\n",
    "\n",
    "### 超参定义区 ###\n",
    "num_epochs = 10\n",
    "#################\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), momentum=0.937, lr=0.01)\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)    # 统一在GPU上面训练\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 用tqdm装饰训练迭代\n",
    "    with tqdm(train_iter, desc=f'Epoch {epoch}/{num_epochs - 1}') as tepoch:\n",
    "        for inputs, labels in tepoch:\n",
    "            # 前向传播\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            # 反向传播及优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 更新tqdm显示的loss\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4、预测\n",
    "for inputs, labels in test_iter:\n",
    "    output = model(inputs.to(device))\n",
    "    output = F.softmax(output, dim=1)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型（可选）\n",
    "\n",
    "# torch.save(model, 'IAN.pt')  # 模型的图结构一并保存\n",
    "torch.save(model.state_dict(), 'IAN.pth')  # 仅保存模型的参数\n",
    "print(f'Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测其他数据集(独立于以上步骤)\n",
    "\n",
    "# 加载模型\n",
    "# loaded_model = IAN()    # 初始化模型结构,在加载仅保存参数的模型时需要\n",
    "device = \"cuda:0\"\n",
    "# loaded_model.load_state_dict(torch.load('IAN.pth'))  # 加载仅保存参数的模型\n",
    "loaded_model = torch.load('IAN.pt')   # 加载完整图结构模型\n",
    "loaded_model.eval()\n",
    "loaded_model.to(device)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "test_path = r\"D:\\BaiduNetdiskDownload\\FLIR_ADAS_1_3\\aligned\\ImageFolder\\test\"   # 文件夹必须按imageFolder格式，即要有class子文件夹，否则会报错。class子文件夹最好正确，以验证性能，若class子文件夹错误，只能自己对着结果分析了\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_path, transform=transform_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "for inputs, labels in test_iter:\n",
    "    output = loaded_model(inputs.to(device))     # 结果是模型预测的输出，取决于模型好坏，不取决于class子文件夹\n",
    "    output = F.softmax(output, dim=1)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = softmax_score[0,:]   # (b, 2)   只取一个试验\n",
    "print(w.shape)\n",
    "x = torch.Tensor(2, 128, 64, 64)\n",
    "f = nn.Linear(2, 2, True)\n",
    "f = f(w)    # 这样调用全连接层才合理，也可以叫线性映射\n",
    "print(f.shape)\n",
    "# print(x[0,:,:,0].shape) # 全取的部分用冒号替代，对齐的部分按序号取值\n",
    "y = torch.add(x[0,:]*f[0], x[1,:]*f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试给自己模型初始化\n",
    "\n",
    "# 加载模型\n",
    "loaded_model = IAN()    # 要运行一下class IAN \n",
    "model_path = 'IAN.pth'\n",
    "device = \"cuda:0\"\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['Conv1.0.weight', 'Conv1.0.bias', 'Conv2.0.weight', 'Conv2.0.bias', 'FC1.weight', 'FC1.bias', 'FC2.weight', 'FC2.bias', 'FC3.weight', 'FC3.bias'])\n",
      "Transferred 10 items\n"
     ]
    }
   ],
   "source": [
    "from models.yolo_test import Model\n",
    "\n",
    "model = Model(\"/project/multispectral-object-detection/models/my_test/yolov5l_illumination_FLIR_v5.yaml\", ch=3, nc=3).to(\"cuda:7\")  # 模型实例\n",
    "# print(model)\n",
    "\n",
    "state_dict = torch.load(\"IAN.pth\")  # 预训练模型\n",
    "print(state_dict.keys()) \n",
    "# odict_keys(['Conv1.0.weight', 'Conv1.0.bias', 'Conv2.0.weight', 'Conv2.0.bias', 'FC1.weight', 'FC1.bias', 'FC2.weight', 'FC2.bias', 'FC3.weight', 'FC3.bias'])\n",
    "# 需要的格式\n",
    "# \"model.20.Conv1.0.weight\", \"model.20.Conv1.0.bias\", \"model.20.Conv2.0.weight\", \"model.20.Conv2.0.bias\", \"model.20.FC1.weight\", \"model.20.FC1.bias\", \"model.20.FC2.weight\", \"model.20.FC2.bias\",\n",
    "\n",
    "new_state_dict = {}     # 训练模型的权重表\n",
    "# new_state_dict[\"model.20.illumination.Conv1.conv.weight\"] = state_dict[\"illumination.Conv1.conv.weight\"]    # 示例,通过指定键值匹配.关键是训练模型的权重表获取到正确的预训练模型的层\n",
    "for key in state_dict.keys():   # 主要操作\n",
    "  new_state_dict['model.20.' + key] = state_dict[key]\n",
    "model.load_state_dict(new_state_dict, strict=False) # strict=True 只有model的全部键都迁移了才不会报错,不然会报错显示什么键未迁移.可用于检查什么键未迁移,是否符合想象\n",
    "# 本质: load_state_dict 将 state_dict这种格式的数据 从 字典new_state_dict 加载到 训练模型model 中, 字典new_state_dict 先通过键值匹配把权重迁移过来\n",
    "\n",
    "print('Transferred %g items' % len(new_state_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning RGB '/project/datasets/FLIR_aligned/visible/test.cache' images and labels... 1013 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 1013/1013 [00:00<?, ?it/s]\n",
      "Scanning IR '/project/datasets/FLIR_aligned/visible/test.cache' images and labels... 1013 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 1013/1013 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m gt_bboxes \u001b[38;5;241m=\u001b[39m targets[:, \u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# print(gt_bboxes.shape)  # 应该输出 torch.Size([81, 4])\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print(gt_bboxes[0])  \u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m m_y \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_elipsis_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs_rgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m, m_y)\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mcreate_elipsis_mask\u001b[0;34m(bboxes, img_shape, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_bboxes)\n\u001b[1;32m     16\u001b[0m mask_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((n, h, w))\n\u001b[0;32m---> 17\u001b[0m xmin, ymin, xmax, ymax \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_bboxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, batch_bboxes[:, \u001b[38;5;241m1\u001b[39m], batch_bboxes[:, \u001b[38;5;241m2\u001b[39m], batch_bboxes[:, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     18\u001b[0m a \u001b[38;5;241m=\u001b[39m (xmax \u001b[38;5;241m-\u001b[39m xmin)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     19\u001b[0m b \u001b[38;5;241m=\u001b[39m (ymax \u001b[38;5;241m-\u001b[39m ymin)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "from train import create_dataloader_rgb_ir\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "EPSILON = 1e-5\n",
    "\n",
    "def gaus2d(xx, yy, mux=0, muy=0, sigx=1, sigy=1, A=1):\n",
    "    return A*torch.exp(-((xx - mux)**2. / (2. * sigx**2.) + (yy - muy)**2. / (2. * sigy**2.)))\n",
    "\n",
    "def create_elipsis_mask(bboxes, img_shape, mode=1):\n",
    "    bs, c, h, w = img_shape\n",
    "    mask = torch.zeros((bs, h, w), device='cuda')\n",
    "    for i, batch_bboxes in enumerate(bboxes):\n",
    "        n = len(batch_bboxes)\n",
    "        mask_ = torch.zeros((n, h, w))\n",
    "        xmin, ymin, xmax, ymax = batch_bboxes[:, 0], batch_bboxes[:, 1], batch_bboxes[:, 2], batch_bboxes[:, 3]\n",
    "        a = (xmax - xmin)/2\n",
    "        b = (ymax - ymin)/2\n",
    "        cx = (xmax + xmin)/2\n",
    "        cy = (ymax + ymin)/2\n",
    "\n",
    "        x = torch.tensor(np.arange(0, w, 1), device='cuda:0')\n",
    "        y = torch.tensor(np.arange(0, h, 1), device='cuda:0')\n",
    "        xx, yy = torch.meshgrid(x, y, indexing='xy')\n",
    "\n",
    "        for j in range(n):\n",
    "            # binary mask\n",
    "            if mode == 1:\n",
    "                m_ = (xx-cx[j])**2/a[j]**2 + (yy-cy[j])**2/b[j]**2 < 1+EPSILON\n",
    "                m_.to(dtype=torch.float32)\n",
    "                mask_[j, :, :] = m_\n",
    "            else:\n",
    "                # gauss heatmap\n",
    "                gauss_map = gaus2d(xx, yy, cx[j], cy[j], a[j], b[j])\n",
    "                mask_[j, :, :] = gauss_map.clone().detach()\n",
    "\n",
    "\n",
    "        mask[i, :, :] = mask_.sum(0).clamp_(min=0, max=1)\n",
    "        # mask[i, :, :] = mask_.sum(0)\n",
    "\n",
    "    return mask\n",
    "train_path_rgb = \"/project/datasets/FLIR_aligned/visible/test\"\n",
    "train_path_ir = \"/project/datasets/FLIR_aligned/infrared/test\"\n",
    "\n",
    "class opt():\n",
    "    single_cls = False\n",
    "\n",
    "dataloader, dataset = create_dataloader_rgb_ir(train_path_rgb, train_path_ir, 640, 8, 32, opt)\n",
    "for i, (imgs, targets, paths, _) in enumerate(dataloader):\n",
    "    imgs_rgb = imgs[:, :3, :, :]\n",
    "    imgs_ir = imgs[:, 3:, :, :]\n",
    "    # print(targets.shape)\n",
    "    # print(targets[0])\n",
    "    gt_bboxes = targets[:, 2:]\n",
    "    # print(gt_bboxes.shape)  # 应该输出 torch.Size([81, 4])\n",
    "    # print(gt_bboxes[0])  \n",
    "    m_y = create_elipsis_mask(gt_bboxes, imgs_rgb.shape, mode=1)\n",
    "    cv2.imshow(\"mask\", m_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "Mask shape: torch.Size([1, 100, 100])\n",
      "Image saved to mask_images.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义 EPSILON 常量\n",
    "EPSILON = 1e-5\n",
    "\n",
    "# 定义 gaus2d 函数（假设这是高斯热图的实现）\n",
    "def gaus2d(xx, yy, mux=0, muy=0, sigx=1, sigy=1, A=1):\n",
    "    return A*torch.exp(-((xx - mux)**2. / (2. * sigx**2.) + (yy - muy)**2. / (2. * sigy**2.)))\n",
    "\n",
    "# 示例数据\n",
    "bs = 1  # 批量大小\n",
    "c = 3   # 通道数\n",
    "h = 100 # 图像高度\n",
    "w = 100 # 图像宽度\n",
    "img_shape = (bs, c, h, w)\n",
    "\n",
    "# 生成一些边界框 (bboxes)\n",
    "# 格式为 [xmin, ymin, xmax, ymax]\n",
    "bboxes = [\n",
    "    torch.tensor([[10, 10, 40, 40], [60, 60, 90, 90]], device='cuda:0')  # 两个边界框\n",
    "]\n",
    "# print(bboxes[0].shape)\n",
    "\n",
    "# 调用 create_elipsis_mask 函数\n",
    "mask = create_elipsis_mask(bboxes, img_shape, mode=1)\n",
    "\n",
    "# 打印掩码的形状\n",
    "print(\"Mask shape:\", mask.shape)\n",
    "\n",
    "# 显示掩码\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# 显示第一个边界框的掩码\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mask[0].cpu().numpy(), cmap='gray')\n",
    "plt.title('Binary Mask (Mode 1)')\n",
    "\n",
    "# 显示第二个边界框的掩码\n",
    "mask_gauss = create_elipsis_mask(bboxes, img_shape, mode=2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_gauss[0].cpu().numpy(), cmap='gray')\n",
    "plt.title('Gaussian Heatmap (Mode 2)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图像到文件\n",
    "output_filename = 'mask_images.png'\n",
    "plt.savefig(output_filename)\n",
    "print(f\"Image saved to {output_filename}\")\n",
    "\n",
    "# 关闭图形以释放内存\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
